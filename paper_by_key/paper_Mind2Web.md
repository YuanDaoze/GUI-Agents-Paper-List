# Papers with Keyword: Mind2Web

- [From Grounding to Planning: Benchmarking Bottlenecks in Web Agents](https://arxiv.org/abs/2409.01927)
    - Segev Shlomov, Ben Wiesel, Aviad Sela, Ido Levy, Liane Galanti, Roy Abitbol
    - ğŸ›ï¸ Institutions: IBM
    - ğŸ“… Date: September 3, 2024
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Web]
    - ğŸ”‘ Key: [benchmark], [planning], [grounding], [Mind2Web dataset], [web navigation]
    - ğŸ“– TLDR: This paper analyzes performance bottlenecks in web agents by separately evaluating grounding and planning tasks, isolating their individual impacts on navigation efficacy. Using an enhanced version of the Mind2Web dataset, the study reveals planning as a significant bottleneck, with advancements in grounding and task-specific benchmarking for elements like UI component recognition. Through experimental adjustments, the authors propose a refined evaluation framework, aiming to enhance web agents' contextual adaptability and accuracy in complex web environments.

- [Identifying User Goals from UI Trajectories](https://arxiv.org/abs/2406.14314)
    - Omri Berkovitch, Sapir Caduri, Noam Kahlon, Anatoly Efros, Avi Caciularu, Ido Dagan
    - ğŸ›ï¸ Institutions: Google Research, Bar-Ilan University
    - ğŸ“… Date: June 20, 2024
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [GUI]
    - ğŸ”‘ Key: [evaluation metric], [intent identification], [Android-In-The-Wild], [Mind2Web]
    - ğŸ“– TLDR: This paper introduces the task of goal identification from observed UI trajectories, aiming to infer the user's intended task based on their GUI interactions. It proposes a novel evaluation metric to assess whether two task descriptions are paraphrases within a specific UI environment. Experiments utilizing the Android-In-The-Wild and Mind2Web datasets reveal that state-of-the-art models, such as GPT-4 and Gemini-1.5 Pro, underperform compared to humans, indicating significant room for improvement.

- [WebCanvas: Benchmarking Web Agents in Online Environments](https://arxiv.org/abs/2406.12373)
    - Yichen Pan, Dehan Kong, Sida Zhou, Cheng Cui, Yifei Leng, Bing Jiang, Hangyu Liu, Yanyi Shang, Shuyan Zhou, Tongshuang Wu, Zhengyang Wu
    - ğŸ›ï¸ Institutions: Zhejiang University, iMean AI, University of Washington
    - ğŸ“… Date: June 18, 2024
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Web]
    - ğŸ”‘ Key: [framework], [dataset], [benchmark], [Mind2Web-Live], [key-node evaluation]
    - ğŸ“– TLDR: This paper presents WebCanvas, an online evaluation framework for web agents designed to address the dynamic nature of web interactions. It introduces a key-node-based evaluation metric to capture critical actions or states necessary for task completion while disregarding noise from insignificant events or changed web elements. The framework includes the Mind2Web-Live dataset, a refined version of the original Mind2Web static dataset, containing 542 tasks with 2,439 intermediate evaluation states. Despite advancements, the best-performing model achieves a task success rate of 23.1%, highlighting substantial room for improvement.

- [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://osu-nlp-group.github.io/SeeAct/)
    - Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, Yu Su
    - ğŸ›ï¸ Institutions: OSU
    - ğŸ“… Date: January 1, 2024
    - ğŸ“‘ Publisher: ICML 2024
    - ğŸ’» Env: [Web]
    - ğŸ”‘ Key: [framework], [dataset], [benchmark], [grounding], [SeeAct], [Multimodal-Mind2web], [Mind2Web]
    - ğŸ“– TLDR: This paper explores the capability of GPT-4V(ision), a multimodal model, as a web agent that can perform tasks across various websites by following natural language instructions. It introduces the **SEEACT** framework, enabling GPT-4V to navigate, interpret, and interact with elements on websites. Evaluated using the **Mind2Web** benchmark and an online test environment, the framework demonstrates high performance on complex web tasks by integrating grounding strategies like element attributes and image annotations to improve HTML element targeting. However, grounding remains challenging, presenting opportunities for further improvement.

- [Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070)
    - Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang, Huan Sun, Yu Su
    - ğŸ›ï¸ Institutions: OSU
    - ğŸ“… Date: June 9, 2023
    - ğŸ“‘ Publisher: NeurIPS 2023
    - ğŸ’» Env: [Web]
    - ğŸ”‘ Key: [dataset], [benchmark], [model], [Mind2Web], [MindAct]
    - ğŸ“– TLDR: *Mind2Web* presents a dataset and benchmark specifically crafted for generalist web agents capable of performing language-guided tasks across varied websites. Featuring over 2,000 tasks from 137 sites, it spans 31 domains and emphasizes open-ended, realistic tasks in authentic, unsimplified web settings. The study proposes the *MindAct* framework, which optimizes LLMs for handling complex HTML elements by using small LMs to rank elements before full processing, thereby enhancing the efficiency and versatility of web agents in diverse contexts.
